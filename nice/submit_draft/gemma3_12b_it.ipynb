{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":89659,"databundleVersionId":11522106,"sourceType":"competition"},{"sourceId":11123842,"sourceType":"datasetVersion","datasetId":6936975},{"sourceId":224423433,"sourceType":"kernelVersion"},{"sourceId":104453,"sourceType":"modelInstanceVersion","modelInstanceId":72256,"modelId":76277},{"sourceId":282751,"sourceType":"modelInstanceVersion","modelInstanceId":239470,"modelId":222398},{"sourceId":282767,"sourceType":"modelInstanceVersion","modelInstanceId":239473,"modelId":222398}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook implements a submission with Gemma 3 12B IT model with some helper code to ensure the generated SVGs conform to the submission requirements. (See the [Evaluation](https://www.kaggle.com/competitions/drawing-with-llms/overview/evaluation) page for details on the submission requirements.)\n\nTo use this notebook interactively, you'll need to install some dependencies. First, *turn on* the Internet under **Session options** to the right. Then select the **Add-ons->Install Dependencies** menu above and click *Run*. A console should pop up with a running `pip` command. Wait for the dependencies to finish installing and then *turn off* the Internet before submitting.","metadata":{}},{"cell_type":"code","source":"ls /kaggle/input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:13:04.370029Z","iopub.execute_input":"2025-03-28T16:13:04.370318Z","iopub.status.idle":"2025-03-28T16:13:04.490652Z","shell.execute_reply.started":"2025-03-28T16:13:04.370293Z","shell.execute_reply":"2025-03-28T16:13:04.489628Z"}},"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34md\u001b[0m/  \u001b[01;34mdrawing-with-llms\u001b[0m/  \u001b[01;34mgemma-2\u001b[0m/  \u001b[01;34mgemma-3\u001b[0m/  \u001b[01;34msvg-constraints\u001b[0m/\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install bitsandbytes cairosvg google_re2\n!pip install --upgrade transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:13:04.492103Z","iopub.execute_input":"2025-03-28T16:13:04.492443Z","iopub.status.idle":"2025-03-28T16:13:24.397180Z","shell.execute_reply.started":"2025-03-28T16:13:04.492407Z","shell.execute_reply":"2025-03-28T16:13:24.396298Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting cairosvg\n  Downloading CairoSVG-2.7.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting google_re2\n  Downloading google_re2-1.1.20240702-1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nCollecting cairocffi (from cairosvg)\n  Downloading cairocffi-1.7.1-py3-none-any.whl.metadata (3.3 kB)\nCollecting cssselect2 (from cairosvg)\n  Downloading cssselect2-0.8.0-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cairosvg) (11.0.0)\nRequirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.4.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi->cairosvg) (1.17.1)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2->cairosvg) (0.5.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading CairoSVG-2.7.1-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_re2-1.1.20240702-1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (546 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m546.8/546.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cairocffi-1.7.1-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cssselect2-0.8.0-py3-none-any.whl (15 kB)\nInstalling collected packages: google_re2, cssselect2, cairocffi, cairosvg, bitsandbytes\nSuccessfully installed bitsandbytes-0.45.4 cairocffi-1.7.1 cairosvg-2.7.1 cssselect2-0.8.0 google_re2-1.1.20240702\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting transformers\n  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.50.2-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed transformers-4.50.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\n\nprint(torch.__version__)\nprint(torch.cuda.is_available())\nprint(torch.cuda.device_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:13:24.398974Z","iopub.execute_input":"2025-03-28T16:13:24.399227Z","iopub.status.idle":"2025-03-28T16:13:27.800706Z","shell.execute_reply.started":"2025-03-28T16:13:24.399202Z","shell.execute_reply":"2025-03-28T16:13:27.799976Z"}},"outputs":[{"name":"stdout","text":"2.5.1+cu121\nTrue\n2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n!export CUDA_VISIBLE_DEVICES=0  # Choose specific GPU for running\n# !export CUDA_LAUNCH_BLOCKING=1\n!export TORCH_USE_CUDA_DSA=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:13:27.801753Z","iopub.execute_input":"2025-03-28T16:13:27.802147Z","iopub.status.idle":"2025-03-28T16:13:28.156302Z","shell.execute_reply.started":"2025-03-28T16:13:27.802124Z","shell.execute_reply":"2025-03-28T16:13:28.155317Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#| export\nimport os\n\n# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\nos.environ['TORCH_USE_CUDA_DSA'] = '1'\n\nimport concurrent\nimport io\nimport logging\nimport re\nimport re2\n\nimport cairosvg\nimport kagglehub\nimport torch\nfrom lxml import etree\nfrom transformers import AutoTokenizer, BitsAndBytesConfig, Gemma3ForCausalLM\n\nsvg_constraints = kagglehub.package_import('metric/svg-constraints')\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass Model:\n    def __init__(self):\n        # Quantization Configuration\n        # quantization_config = BitsAndBytesConfig(\n        #     load_in_4bit=True,\n        #     bnb_4bit_quant_type=\"nf4\",\n        #     bnb_4bit_use_double_quant=True,\n        #     bnb_4bit_compute_dtype=torch.float16,\n        # )\n        quantization_config = BitsAndBytesConfig(\n            load_in_8bit=True,\n        )\n        \n        self.model_path = kagglehub.model_download('google/gemma-3/transformers/gemma-3-12b-it/1')\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n\n        # self.model = Gemma3ForCausalLM.from_pretrained(\n        #     self.model_path,\n        #     quantization_config=quantization_config,\n        #     device_map=\"auto\",\n        #     low_cpu_mem_usage=True\n        # )\n        # self.model = Gemma3ForCausalLM.from_pretrained(\n        #     self.model_path,\n        #     quantization_config=quantization_config,\n        #     device_map=\"auto\"\n        # )\n        # Use float16 or bfloat16 to load the model\n        self.model = Gemma3ForCausalLM.from_pretrained(\n            self.model_path,\n            device_map=\"auto\",\n            torch_dtype=torch.bfloat16,  # or torch.float16\n        )\n        self.model.gradient_checkpointing_enable()\n\n        print(self.model.hf_device_map)\n        \n        self.prompt_template = \"\"\"Generate SVG code to visually represent the following text description, while respecting the given constraints.\n<constraints>\n* **Allowed Elements:** `svg`, `path`, `circle`, `rect`, `ellipse`, `line`, `polyline`, `polygon`, `g`, `linearGradient`, `radialGradient`, `stop`, `defs`\n* **Allowed Attributes:** `viewBox`, `width`, `height`, `fill`, `stroke`, `stroke-width`, `d`, `cx`, `cy`, `r`, `x`, `y`, `rx`, `ry`, `x1`, `y1`, `x2`, `y2`, `points`, `transform`, `opacity`\n</constraints>\n\n<example>\n<description>\"A red circle with a blue square inside\"</description>\n```svg\n<svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n  <circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/>\n  <rect x=\"30\" y=\"30\" width=\"40\" height=\"40\" fill=\"blue\"/>\n</svg>\n```\n</example>\n\n\nPlease ensure that the generated SVG code is well-formed, valid, and strictly adheres to these constraints. Focus on a clear and concise representation of the input description within the given limitations. Always give the complete SVG code with nothing omitted. Never use an ellipsis.\n\n<description>\"{}\"</description>\n```svg\n<svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n\"\"\"\n#         self.prompt_template = \"\"\"Generate high-quality SVG code to visually represent the given description. Ensure the design is clear, well-structured, and adheres to the specified constraints.\n# <constraints>\n# * **Allowed Elements:** `svg`, `path`, `circle`, `rect`, `ellipse`, `line`, `polyline`, `polygon`, `g`, `linearGradient`, `radialGradient`, `stop`, `defs`\n# * **Allowed Attributes:** `viewBox`, `width`, `height`, `fill`, `stroke`, `stroke-width`, `d`, `cx`, `cy`, `r`, `x`, `y`, `rx`, `ry`, `x1`, `y1`, `x2`, `y2`, `points`, `transform`, `opacity`\n# * **Code Requirements:**\n#   * The generated SVG must be **valid, well-formed**, and free from errors.\n#   * Ensure **correct positioning and scaling** to maintain visual balance.\n#   * Use **appropriate colors, shapes, and proportions** to best represent the description.\n#   * Avoid unnecessary complexity while ensuring visual accuracy.\n#   * The output should be **self-contained and complete**—never use placeholders or omit parts.\n\n# <example>\n# <description>\"A red circle with a blue square inside, centered within a 256x256 canvas\"</description>\n# ```svg\n# <svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\" xmlns=\"http://www.w3.org/2000/svg\">\n#   <circle cx=\"128\" cy=\"128\" r=\"60\" fill=\"red\"/>\n#   <rect x=\"98\" y=\"98\" width=\"60\" height=\"60\" fill=\"blue\"/>\n# </svg>\n# ```\n# </example>\n\n\n# Please ensure that the generated SVG code is well-formed, valid, and strictly adheres to these constraints. Focus on a clear and concise representation of the input description within the given limitations. Always give the complete SVG code with nothing omitted. Never use an ellipsis.\n\n# <description>\"{}\"</description>\n# ```svg\n# <svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n# \"\"\"\n        self.default_svg = \"\"\"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\" /></svg>\"\"\"\n        self.constraints = svg_constraints.SVGConstraints()\n        self.timeout_seconds = 900\n\n    \n    \n    # You could try increasing `max_new_tokens`\n    def predict(self, description: str, max_new_tokens=256) -> str:\n        def generate_svg():\n            try:\n                prompt = self.prompt_template.format(description)\n\n                input_ids_0 = self.tokenizer(text=prompt, return_tensors=\"pt\").to(DEVICE)\n\n                # Clear the GPU cache before generating\n                torch.cuda.empty_cache()\n                try:\n                    with torch.no_grad():\n                        outputs = self.model.generate(\n                            **input_ids_0, \n                            max_new_tokens=max_new_tokens,\n                        )\n                except Exception as e:\n                    print('Exception during output generation: %s', e)\n\n                print('Outputs from model: %s', outputs)\n                output_decoded = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n                \n                logging.debug('Output decoded from model: %s', output_decoded)\n                print('Output decoded from model: %s', output_decoded)\n\n                matches = re.findall(r\"<svg.*?</svg>\", output_decoded, re.DOTALL | re.IGNORECASE)\n                if matches:\n                    svg = matches[-1]\n                else:\n                    return self.default_svg\n\n                logging.debug('Unprocessed SVG: %s', svg)\n                svg = self.enforce_constraints(svg)\n                logging.debug('Processed SVG: %s', svg)\n                # Ensure the generated code can be converted by cairosvg\n                cairosvg.svg2png(bytestring=svg.encode('utf-8'))\n                return svg\n            except Exception as e:\n                logging.error('Exception during SVG generation: %s', e)\n                print('Exception during SVG generation: %s', e)\n                return self.default_svg\n\n        # Execute SVG generation in a new thread to enforce time constraints\n        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n            future = executor.submit(generate_svg)\n            try:\n                return future.result(timeout=self.timeout_seconds)\n            except concurrent.futures.TimeoutError:\n                logging.warning(\"Prediction timed out after %s seconds.\", self.timeout_seconds)\n                return self.default_svg\n            except Exception as e:\n                logging.error(f\"An unexpected error occurred: {e}\")\n                return self.default_svg\n\n    def enforce_constraints(self, svg_string: str) -> str:\n        \"\"\"Enforces constraints on an SVG string, removing disallowed elements\n        and attributes.\n\n        Parameters\n        ----------\n        svg_string : str\n            The SVG string to process.\n\n        Returns\n        -------\n        str\n            The processed SVG string, or the default SVG if constraints\n            cannot be satisfied.\n        \"\"\"\n        logging.info('Sanitizing SVG...')\n\n        try:\n            parser = etree.XMLParser(remove_blank_text=True, remove_comments=True)\n            root = etree.fromstring(svg_string, parser=parser)\n        except etree.ParseError as e:\n            logging.error('SVG Parse Error: %s. Returning default SVG.', e)\n            return self.default_svg\n    \n        elements_to_remove = []\n        for element in root.iter():\n            tag_name = etree.QName(element.tag).localname\n    \n            # Remove disallowed elements\n            if tag_name not in self.constraints.allowed_elements:\n                elements_to_remove.append(element)\n                continue  # Skip attribute checks for removed elements\n    \n            # Remove disallowed attributes\n            attrs_to_remove = []\n            for attr in element.attrib:\n                attr_name = etree.QName(attr).localname\n                if (\n                    attr_name\n                    not in self.constraints.allowed_elements[tag_name]\n                    and attr_name\n                    not in self.constraints.allowed_elements['common']\n                ):\n                    attrs_to_remove.append(attr)\n    \n            for attr in attrs_to_remove:\n                logging.debug(\n                    'Attribute \"%s\" for element \"%s\" not allowed. Removing.',\n                    attr,\n                    tag_name,\n                )\n                del element.attrib[attr]\n    \n            # Check and remove invalid href attributes\n            for attr, value in element.attrib.items():\n                 if etree.QName(attr).localname == 'href' and not value.startswith('#'):\n                    logging.debug(\n                        'Removing invalid href attribute in element \"%s\".', tag_name\n                    )\n                    del element.attrib[attr]\n\n            # Validate path elements to help ensure SVG conversion\n            if tag_name == 'path':\n                d_attribute = element.get('d')\n                if not d_attribute:\n                    logging.warning('Path element is missing \"d\" attribute. Removing path.')\n                    elements_to_remove.append(element)\n                    continue # Skip further checks for this removed element\n                # Use regex to validate 'd' attribute format\n                path_regex = re2.compile(\n                    r'^'  # Start of string\n                    r'(?:'  # Non-capturing group for each command + numbers block\n                    r'[MmZzLlHhVvCcSsQqTtAa]'  # Valid SVG path commands (adjusted to exclude extra letters)\n                    r'\\s*'  # Optional whitespace after command\n                    r'(?:'  # Non-capturing group for optional numbers\n                    r'-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?'  # First number\n                    r'(?:[\\s,]+-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?)*'  # Subsequent numbers with mandatory separator(s)\n                    r')?'  # Numbers are optional (e.g. for Z command)\n                    r'\\s*'  # Optional whitespace after numbers/command block\n                    r')+'  # One or more command blocks\n                    r'\\s*'  # Optional trailing whitespace\n                    r'$'  # End of string\n                )\n                if not path_regex.match(d_attribute):\n                    logging.warning(\n                        'Path element has malformed \"d\" attribute format. Removing path.'\n                    )\n                    elements_to_remove.append(element)\n                    continue\n                logging.debug('Path element \"d\" attribute validated (regex check).')\n        \n        # Remove elements marked for removal\n        for element in elements_to_remove:\n            if element.getparent() is not None:\n                element.getparent().remove(element)\n                logging.debug('Removed element: %s', element.tag)\n\n        try:\n            cleaned_svg_string = etree.tostring(root, encoding='unicode')\n            return cleaned_svg_string\n        except ValueError as e:\n            logging.error(\n                'SVG could not be sanitized to meet constraints: %s', e\n            )\n            return self.default_svg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:13:28.157467Z","iopub.execute_input":"2025-03-28T16:13:28.157842Z","iopub.status.idle":"2025-03-28T16:13:46.395947Z","shell.execute_reply.started":"2025-03-28T16:13:28.157810Z","shell.execute_reply":"2025-03-28T16:13:46.395277Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"The following code tests the above model in a local mock-up of this competition's evaluation pipeline. It runs the model on a sample of 15 instances defined in the `test.csv` file in the `kaggle_evaluation` package folder.","metadata":{}},{"cell_type":"code","source":"import kaggle_evaluation\n\nlogging.basicConfig(level=logging.INFO, force=True)\nkaggle_evaluation.test(Model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:13:46.396755Z","iopub.execute_input":"2025-03-28T16:13:46.397210Z","iopub.status.idle":"2025-03-28T16:17:44.566958Z","shell.execute_reply.started":"2025-03-28T16:13:46.397186Z","shell.execute_reply":"2025-03-28T16:17:44.565595Z"}},"outputs":[{"name":"stdout","text":"Creating Model instance...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83613048e8bc4bcd81eb33455985f424"}},"metadata":{}},{"name":"stdout","text":"{'model.embed_tokens': 0, 'lm_head': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 0, 'model.layers.9': 0, 'model.layers.10': 0, 'model.layers.11': 0, 'model.layers.12': 0, 'model.layers.13': 0, 'model.layers.14': 0, 'model.layers.15': 0, 'model.layers.16': 0, 'model.layers.17': 0, 'model.layers.18': 0, 'model.layers.19': 0, 'model.layers.20': 0, 'model.layers.21': 0, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.layers.32': 1, 'model.layers.33': 1, 'model.layers.34': 1, 'model.layers.35': 1, 'model.layers.36': 1, 'model.layers.37': 1, 'model.layers.38': 1, 'model.layers.39': 1, 'model.layers.40': 1, 'model.layers.41': 1, 'model.layers.42': 1, 'model.layers.43': 1, 'model.layers.44': 1, 'model.layers.45': 1, 'model.layers.46': 1, 'model.layers.47': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'model.rotary_emb_local': 1}\nRunning inference tests...\nWrote test submission file to \"/tmp/kaggle-evaluation-submission-b3yth9xp.csv\".\nSuccess!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Alternatively, you could use the code below to run the model over `train.csv` and see some generated images along with some debugging info. Feel free to turn down the logging level to `INFO` if you just want to see the images.","metadata":{}},{"cell_type":"code","source":"def generate():\n    import polars as pl\n    from IPython.display import SVG\n    import time  # Import the time module\n    \n    logging.basicConfig(level=logging.DEBUG, force=True)\n    \n    train = pl.read_csv('/kaggle/input/drawing-with-llms/train.csv')\n    display(train.head())\n    \n    model = Model()\n    svgs = []\n    total_pred_time = 0.0\n    inf_cnt = 0\n    for desc in train.get_column('description'):\n        start_time = time.time()  # Record start time\n        svg = model.predict(desc, max_new_tokens=256)\n        end_time = time.time()    # Record end time\n        elapsed_time = end_time - start_time # Calculate elapsed time\n        print(f\"Prediction time for description '{desc[:20]}...': {elapsed_time:.4f} seconds\") # Print time\n    \n        try:\n            display(SVG(svg))\n        except Exception as e:\n            print(e)\n            continue\n\n        total_pred_time += elapsed_time\n        inf_cnt += 1\n\n\n    print(f\"Total prediction time: {total_pred_time:.4f} seconds\")\n    print(f\"Average prediction time: {total_pred_time/inf_cnt:.4f} seconds\")\n        \n\n# Uncomment and run the line below to see some generated images\ngenerate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T16:17:44.570034Z","iopub.execute_input":"2025-03-28T16:17:44.570307Z","iopub.status.idle":"2025-03-28T16:18:07.882913Z","shell.execute_reply.started":"2025-03-28T16:17:44.570285Z","shell.execute_reply":"2025-03-28T16:18:07.882156Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"shape: (5, 2)\n┌────────┬─────────────────────────────────┐\n│ id     ┆ description                     │\n│ ---    ┆ ---                             │\n│ str    ┆ str                             │\n╞════════╪═════════════════════════════════╡\n│ 02d892 ┆ a purple forest at dusk         │\n│ 0dcd2e ┆ gray wool coat with a faux fur… │\n│ 1e9ac1 ┆ a lighthouse overlooking the o… │\n│ 2b25db ┆ burgundy corduroy pants with p… │\n│ 4e6a54 ┆ orange corduroy overalls        │\n└────────┴─────────────────────────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>description</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;02d892&quot;</td><td>&quot;a purple forest at dusk&quot;</td></tr><tr><td>&quot;0dcd2e&quot;</td><td>&quot;gray wool coat with a faux fur…</td></tr><tr><td>&quot;1e9ac1&quot;</td><td>&quot;a lighthouse overlooking the o…</td></tr><tr><td>&quot;2b25db&quot;</td><td>&quot;burgundy corduroy pants with p…</td></tr><tr><td>&quot;4e6a54&quot;</td><td>&quot;orange corduroy overalls&quot;</td></tr></tbody></table></div>"},"metadata":{}},{"name":"stderr","text":"DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): dp.kaggle.net:443\nDEBUG:urllib3.connectionpool:https://dp.kaggle.net:443 \"POST /kaggle-jwt-handler/AttachDatasourceUsingJwtRequest HTTP/1.1\" 200 None\nINFO:accelerate.utils.modeling:Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:\n  - 0: 2462055424 bytes required\nThese minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8ec1c2c082a41a094ab8ed907b4c017"}},"metadata":{}},{"name":"stderr","text":"WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n","output_type":"stream"},{"name":"stdout","text":"{'model.embed_tokens': 1, 'lm_head': 1, 'model.layers.0': 1, 'model.layers.1': 1, 'model.layers.2': 1, 'model.layers.3': 1, 'model.layers.4': 'cpu', 'model.layers.5': 'cpu', 'model.layers.6': 'cpu', 'model.layers.7': 'cpu', 'model.layers.8': 'cpu', 'model.layers.9': 'cpu', 'model.layers.10': 'cpu', 'model.layers.11': 'cpu', 'model.layers.12': 'cpu', 'model.layers.13': 'cpu', 'model.layers.14': 'cpu', 'model.layers.15': 'cpu', 'model.layers.16': 'cpu', 'model.layers.17': 'cpu', 'model.layers.18': 'cpu', 'model.layers.19': 'cpu', 'model.layers.20': 'cpu', 'model.layers.21': 'cpu', 'model.layers.22': 'cpu', 'model.layers.23': 'cpu', 'model.layers.24': 'cpu', 'model.layers.25': 'cpu', 'model.layers.26': 'cpu', 'model.layers.27': 'cpu', 'model.layers.28': 'cpu', 'model.layers.29': 'cpu', 'model.layers.30': 'cpu', 'model.layers.31': 'cpu', 'model.layers.32': 'cpu', 'model.layers.33': 'cpu', 'model.layers.34': 'cpu', 'model.layers.35': 'cpu', 'model.layers.36': 'cpu', 'model.layers.37': 'cpu', 'model.layers.38': 'cpu', 'model.layers.39': 'cpu', 'model.layers.40': 'cpu', 'model.layers.41': 'cpu', 'model.layers.42': 'cpu', 'model.layers.43': 'cpu', 'model.layers.44': 'cpu', 'model.layers.45': 'cpu', 'model.layers.46': 'cpu', 'model.layers.47': 'cpu', 'model.norm': 'cpu', 'model.rotary_emb': 'cpu', 'model.rotary_emb_local': 'cpu'}\n","output_type":"stream"},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 2.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'a purple forest at d...': 0.2092 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'gray wool coat with ...': 0.0165 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 2.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'a lighthouse overloo...': 0.0164 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'burgundy corduroy pa...': 0.0157 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 2.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'orange corduroy over...': 0.0146 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'a purple silk scarf ...': 0.0148 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'a green lagoon under...': 0.0151 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'crimson rectangles f...': 0.0169 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'purple pyramids spir...': 0.0167 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'magenta trapezoids l...': 0.0162 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 2.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'a snowy plain...': 0.0153 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 2.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'black and white chec...': 0.0181 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stdout","text":"Exception during output generation: %s ","output_type":"stream"},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'a starlit night over...': 0.0172 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","output_type":"stream"},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'khaki triangles and ...': 0.0173 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stderr","text":"ERROR:root:Exception during SVG generation: local variable 'outputs' referenced before assignment\n","output_type":"stream"},{"name":"stdout","text":"Exception during output generation: %s CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3191 has 14.72 GiB memory in use. Of the allocated memory 14.61 GiB is allocated by PyTorch, and 1.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\nException during SVG generation: %s local variable 'outputs' referenced before assignment\nPrediction time for description 'a maroon dodecahedro...': 0.0148 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>","image/svg+xml":"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/></svg>"},"metadata":{}},{"name":"stdout","text":"Total prediction time: 0.4347 seconds\nAverage prediction time: 0.0290 seconds\n","output_type":"stream"}],"execution_count":7}]}